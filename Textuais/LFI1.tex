\chapter{A Lógica de Inconsistência Formal LFI1}
\label{cap:LFI1}

Com os avanços da internet no contexto do gerenciamento de bancos de dados, informações passaram a ser coletadas a partir de diferentes fontes que frequentemente se contradizem. Dada a existência das restrições de integridade {--} que impedem contradições {--} a atualização e manutenção de bancos de dados se torna um processo difícil~\cite{carnielli2000formal}. Portanto, uma lógica capaz de lidar com informações inconsistentes sem necessariamente sofrer com a trivialidade é de grande interesse. A lógica de inconsistência formal \lfium{} é capaz de lidar com contradições ao introduzir na sua assinatura o operador $\circ$ para representar a consistência, internalizando este conceito em sua linguagem. Uma informação é dita consistente caso ela e sua negação não sejam simultaneamente verdadeiras, ou seja, dada uma informação $\alpha$, sua consistência $\circ \alpha$ será equivalente a fórmula $\neg (\alpha \land \neg \alpha)$. Com a introdução deste novo operador, é possível lidar com a inconsistência de informações sem que trivialidade ocorra, já que {-} caso uma informação seja conhecidamente \textit{inconsistente}, ou seja, $\neg \circ \alpha$ {-} então ela se trata de uma contradição inofensiva, fruto do excesso de informações numa dada teoria. Com isso, na \lfium{}, o conjunto $\bigcirc(p)$ de fórmulas dependentes somente na variável $p$ (descrito na Definição~\ref{def:lfi}) assume forma $\{\circ p\}$.

No trabalho de~\citeshort{carnielli2000formal} a lógica \textbf{LFI1*} é definida como uma extensão de primeira ordem da lógica proposicional \lfium{}. A motivação para definir-se uma \textit{Lógica de Inconsistência Formal} de primeira ordem vem da natureza das informações contidas em bancos de dados, estas que podem ser compreendidas como sentenças de primeira ordem fixas~\cite{Codd}, entretanto, o presente trabalho trata somente da lógica proposicional \lfium{}. Ademais,~\citeshort{carnielli2000formal} tomam o operador de \textit{inconsistência} (denotado por $\bullet$) como primitivo. Isto foi feito pois o foco era explorar a \lfium{} como uma ferramenta para lidar com inconsistências em bancos de dados, portanto tomar a inconsistência como primitiva era de grande interesse. Entretanto, no presente trabalho, será utilizada a definição apresentada em~\citeshort{Carnielli_Coniglio_2016}, onde a linguagem é definida utilizando o operador $\circ$ como primitivo. Isto salienta algumas propriedades interessantes da negação $\neg$, como a presença das leis de De Morgan, axiomatizadas na Seção~\ref{sec:axiomatizacao}.

Este capítulo é dividido da seguinte forma: na Seção~\ref{sec:linguagem} é apresentada a linguagem da lógica proposicional \lfium{} bem como definições necessárias para desenvolver as provas de metateoremas. A Seção~\ref{sec:axiomatizacao} contém uma breve explicação sobre sistemas de prova sintáticos e uma Axiomatização de Hilbert para a \lfium{} é definida. Na Seção~\ref{sec:semantica} a semântica da \lfium{} é definida a partir de matrizes lógicas e de uma semântica de valorações não determinística, assim como é provada a equivalência entre essas duas semânticas.

\section{Linguagem}
\label{sec:linguagem}
    A lógica proposicional \lfium{} aqui apresentada é definida com base em~\citeshort{Carnielli_Coniglio_2016} sobre a linguagem $\pazocal{L}_{\Sigma}$, que por sua vez é definida sobre um conjunto enumerável de átomos $\pazocal{P} = \{p_{n} \;|\; n \in \mathbb{N}\}$ e uma assinatura proposicional $\Sigma = \{\land^{2}, \lor^{2}, \to^{2}, \neg^{1}, \circ^{1}\}$. Como de costume, o conectivo $\land^{2}$ representa uma conjunção, $\lor^{2}$ representa uma disjunção, $\to^{2}$ representa uma implicação, $\neg^{1}$ representa uma negação e $\circ^{1}$ é o conectivo de consistência, definido de forma primitiva. No restante do texto a aridade destes conectivos será omitida. A linguagem $\pazocal{L}_{\Sigma}$ da \lfium{} é definida da seguinte forma:

    \begin{definicao}[Linguagem da \lfium{}]
        A linguagem $\pazocal{L}_{\Sigma}$ da \lfium{} é definida indutivamente como o menor conjunto a que respeita as seguintes regras:
        \label{def:ling}
        \begin{align*}
            & \text{1.~}\pazocal{P} \subseteq \pazocal{L}_{\Sigma}                                                                                                                        \\
            & \text{2.~Se } \phi \in \pazocal{L}_{\Sigma}, \text{então } \triangle  \phi \in \pazocal{L}_{\Sigma}, \text{com } \triangle \in \{\neg, \circ\}                            \\
            & \text{3.~Se } \phi, \psi \in \pazocal{L}_{\Sigma}, \text{então } \phi \otimes \psi \in \pazocal{L}_{\Sigma}, \text{com } \otimes \in \{\land, \lor, \to\} \tag*\qed
        \end{align*}
    \end{definicao}

    A precedência dos conectivos é dada de maneira costumeira, com a adição do operador $\circ$ de consistência, seguindo a ordem (da maior precedência para a menor): $\circ$, $\neg$, $\land$, $\lor$, $\to$. Os conectivos binários $\land$ e $\lor$ são associativos à esquerda, ou seja, uma expressão do tipo $\alpha \land \beta \land \gamma$ é lida como $((\alpha \land \beta) \land \gamma)$, e o conectivo $\to$ é associativo à direita, ou seja, uma expressão do tipo $\alpha \to \beta \to \gamma$ é lida como $(\alpha \to (\beta \to \gamma))$.

    A linguagem da \lfium{} pode ser definida de maneira equivalente utilizando-se o operador de inconsistência (representado por $\bullet$), definido como $\bullet \alpha \eqdef \neg \circ \alpha$, como feito por~\citeshort{carnielli2000formal}. 

    % \begin{definicao}[Subfórmulas]
    %     \label{def:subf}
    %     O conjunto Sub$(\phi)$ de subfórmulas de uma fórmula $\phi$ é definido indutivamente da seguinte forma:
    %     \begin{align*}
    %          & \text{1.~Sub}(p_{i}) = \{p_{i}\}, \; p_{i} \in \pazocal{P}                                                                                                            \\
    %          & \text{2.~Sub}(\triangle \phi) = \{\triangle \phi\} \; \cup \;\text{Sub}(\phi), \; \triangle \in \{\neg, \circ\}                                                     \\
    %          & \text{3.~Sub}(\phi \otimes \psi) = \{\phi \otimes \psi\} \; \cup \;\text{Sub}(\phi) \; \cup \;\text{Sub}(\psi), \; \otimes \in \{\land, \lor, \to\} \tag*\qed
    %     \end{align*}
    % \end{definicao}


    Na Definição~\ref{def:complex} a função $C$ da complexidade de uma fórmula na lógica proposicional clássica foi recursivamente definida. É possível estender esta definição para identificar a complexidade de uma fórmula na \lfium{} adicionando-se uma condição para o operador $\circ$:

    \begin{definicao}[Complexidade de uma fórmula na \lfium{}]
        Dada uma fórmula $\phi \in \pazocal{L}_{\Sigma}$, a complexidade $C(\phi)$ é definida adicionando-se a seguinte condição à Definição~\ref{def:complex}:
        \label{def:complex_lfi1}
        \begin{align*}
            & \text{Se } \phi = \circ \psi \text{, então } C(\phi) = C(\psi) + 2.\tag*\qed{}
        \end{align*}
        
    \end{definicao}

    Note que a complexidade de uma fórmula do tipo $\circ \alpha$ é estritamente maior que a complexidade de $\alpha$ e $\neg \alpha$. Isto se dá pois, como evidenciado pela semântica de valorações na Definição~\ref{def:valoracoes}, exite uma dependência de $\circ \alpha$ em $\{\alpha, \neg \alpha\}$, como apresentada por~\citeshort{Carnielli_Coniglio_2016}.

\section{Axiomatização}
\label{sec:axiomatizacao}

    A teoria das provas é uma das abordagens para o estudo das relações de consequência, onde a validade de uma inferência é atestada caso haja uma \textit{prova} das conclusões a partir das premissas. Uma \textit{prova} consiste em uma sequência de passos bem definidos aplicados sobre conjuntos (ocasionalmente unitários) de proposições, com base nos princípios de um determinado sistema de provas. A teoria das provas é sintática\footnote{Vale notar que a separação \textit{prova {--} sintaxe {--} semântica {--} modelo} não é tão bem definida, algo que é explorado em~\citeshort{Prawitz2005-PRALCA-2}.} por natureza, ou seja, numa inferência do tipo $A \vdash B$, é relevante apenas a estrutura das fórmulas presentes em \textit{A} e \textit{B}, não sua interpretação ou valor-verdade. Essa estrutura é manipulada a fim de obter-se uma sequência de passos que {--} além de atestar sua validade {--} serve como argumento para tal~\cite{sep-logical-consequence}. Desta forma, pode-se definir um sistema de provas sintático para servir como relação de consequência para uma determinada lógica. 

    No contexto da \lfium{} existem dois sistemas de prova sintáticos estabelecidos até o momento: um cálculo de Hilbert, descrito por~\citeshort{carnielli2000formal,Carnielli_Coniglio_2016} e um sistema de \textit{Tableau}, descrito por~\citeshort{tableaulfi}. No presente trabalho, foi escolhido o cálculo de Hilbert para definir a sintaxe da \lfium{}, dada a maior facilidade para desenvolver metateoremas em relação ao sistema de \textit{Tableau}.

    O cálculo de Hilbert (também conhecido como sistema de Hilbert ou axiomatização de Hilbert) é um sistema composto por um conjunto de fórmulas, chamadas de \textit{axiomas}, um conjunto de \textit{regras de inferência}. Uma regra de inferência é formada por uma lista de fórmulas chamadas de premissas da regra e uma fórmula chamada de conclusão da regra~\cite{Restall1999-RESAIT-4}. Uma prova (também chamada de derivação) do tipo $\Gamma \vdash \phi$ consiste em uma sequência finita de fórmulas \(\psi_0, \dots, \psi_n\), onde \(\psi_n = \phi\), e cada  $\psi_i\ (0 \leq i \leq n)$ é um axioma, um elemento do conjunto de premissas $\Gamma$ ou o resultado da aplicação de uma regra de inferência em fórmulas anteriores. Usualmente, o cálculo de Hilbert possui apenas uma regra de inferência, esta sendo o \textit{Modus Ponens}. Este também é o caso para o cálculo de Hilbert que será utilizado para a \lfium{}.
    
    O cálculo de Hilbert definido a seguir foi apresentado por~\citeshort{Carnielli_Coniglio_2016} como alternativa ao que havia sido definido em trabalhos anteriores~\cite{carnielli2000formal,carnielli2007}. Segundo os autores, esta definição evidencia algumas propriedades interessantes da negação $\neg$ como as leis de De Morgan.


    \begin{definicao}[\lfium{}]
        \label{def:lfi1}
        A relação de consequência sintática $\conhil{}$ para a lógica \lfium{} é definida sobre a linguagem $\pazocal{L}_{\Sigma}$ através do seguinte cálculo de Hilbert:\helena{explicar os nomes estranhos dos axiomas}

        \noindent\textbf{Axiomas}:
        \begin{align*}
            & \alpha \to (\beta \to \alpha)\tag{\textbf{Ax1}}                                                                                     \\
            & (\alpha \to (\beta \to \gamma)) \to ((\alpha \to \beta) \to (\alpha \to \gamma ))\tag{\textbf{Ax2}} \\
            & \alpha \to (\beta \to (\alpha \land \beta))\tag{\textbf{Ax3}}                                                                       \\
            & (\alpha \land \beta) \to \alpha\tag{\textbf{Ax4}}                                                                                           \\
            & (\alpha \land \beta) \to \beta\tag{\textbf{Ax5}}                                                                                            \\
            & \alpha \to (\alpha \lor \beta)\tag{\textbf{Ax6}}                                                                                            \\
            & \beta \to (\alpha \lor \beta)\tag{\textbf{Ax7}}                                                                                             \\
            & (\alpha \to \gamma) \to ((\beta \to \gamma) \to ((\alpha \lor \beta) \to \gamma))\tag{\textbf{Ax8}}         \\
            & (\alpha \to \beta) \lor \alpha\tag{\textbf{Ax9}}                                                                                           \\
            & \alpha \lor \neg \alpha\tag{\textbf{Ax10}}                                                                                                          \\
            & \circ \alpha \to (\alpha \to (\neg \alpha \to \beta))\tag{\textbf{bc1}}                                                     \\
            & \neg \neg \alpha \to \alpha\tag{\textbf{cf}}
            \\
            & \alpha \to \neg \neg \alpha\tag{\textbf{ce}}
            \\
            & \neg \circ \alpha \to (\alpha \land \neg \alpha)\tag{\textbf{ci}}                                                                           \\
            & \neg (\alpha \lor \beta) \to (\neg \alpha \land \neg \beta)\tag{\textbf{neg}$\lor_{1}$}\\
            & (\neg \alpha \land \neg \beta) \to \neg (\alpha \lor \beta)\tag{\textbf{neg}$\lor_{2}$}\\
            & \neg(\alpha \land \beta) \to (\neg \alpha \lor \neg \beta)\tag{\textbf{neg}$\land_{1}$}\\
            & (\neg \alpha \lor \neg \beta) \to \neg (\alpha \land \beta)\tag{\textbf{neg}$\land_{2}$}\\
            & \neg (\alpha \to \beta) \to(\alpha \land \neg \beta)\tag{\textbf{neg}$\to_{1}$}\\
            & (\alpha \land \neg \beta) \to \neg(\alpha \to \beta)\tag{\textbf{neg}$\to_{2}$}
    \end{align*}
        \\
        \noindent\textbf{Regra de inferência:}
        \begin{prooftree}
            \AxiomC{$\alpha, \alpha \to \beta$}
            \RightLabel{MP}
            \UnaryInfC{$\beta$}
        \end{prooftree}
        \qed{}  
    \end{definicao}

    Com isso, uma derivação em \lfium{} pode ser definida:
    
    \begin{definicao}[Derivação em \lfium{}]
        Seja $\Gamma \cup \{\phi\} \subseteq \pazocal{L}_{\Sigma}$ um conjunto de fórmulas, uma derivação $\Gamma \conhil \phi$ de $\phi$ a partir de $\Gamma$ em \lfium{} é uma sequência finita de fórmulas \(\phi_0, \dots, \phi_n\) onde, para cada $1 \leq i \leq n$, alguma das seguintes condições é satisfeita:
        \begin{align*}
            & \text{~~(i) }\phi_{i} \text{ é um axioma;}\\
            & \text{~(ii) }\phi_{i} \in \Gamma;\\
            & \text{(iii) }\text{existem } j,k < i \text{ de modo que } \phi_{i} \text{ é o resultado da aplicação de MP em } \phi_{j} \text{ e } \phi_{k}.\tag*\qed{}
        \end{align*}
    \end{definicao}

\section{Semântica}
\label{sec:semantica}
    De forma geral, a semântica é o estudo de como um sistema de símbolos (uma linguagem) internaliza informações, ou seja, é o estudo de como interpretar os símbolos de uma linguagem~\cite{brown2005encyclopedia}. Num sistema lógico, \textit{matrizes lógicas} são comumente usadas para estabelecer o comportamento esperado dos conectivos lógicos de sua assinatura. Outra forma de compreender a semântica de um sistema lógico é definir uma função conhecida como \textit{valoração}, que define uma \textit{semântica de valorações}. Nesta seção, a semântica da \lfium{} será definida de dois jeitos distintos: a partir de uma \textit{matriz lógica} e a partir de uma \textit{valoração}. Ambas serão provadas equivalentes, a fim de facilitar a prova de metateoremas na Seção~\ref{sec:metateoremas}. As definições e notações para os conceitos de \textit{álgebra} definidos aqui baseiam-se nos trabalhos de~\citeshort{Carnielli_Coniglio_2016} e de~\citeshort{Sikorski1966-SIKAOF}.
    \subsection{Matriz Lógica e Valoração}
        Uma das formas de definir a semântica de uma lógica proposicional é definir uma \textit{matriz lógica} (também chamada de tabela-verdade) para os conectivos de sua assinatura proposicional. Para isso, é necessário definir o conceito de \textit{álgebra} para assinaturas proposicionais:
        \helena{Sera q eu defino essas coisas em outra seção?} \migs{Não acho que seja necessário abrir outra seção apenas para duas ou três de definições.}

        \begin{definicao}[Álgebra para assinaturas proposicionais]
        \label{def:algebra}
            Uma álgebra para uma assinatura proposicional $\Theta$ é uma dupla $\pazocal{A} = \langle A, O \rangle$, onde $A$ é um conjunto não vazio (chamado de \textit{domínio} da álgebra) e $O$ é uma função de interpretação que associa cada conectivo n-ário $c \in \Theta$ à uma operação $c^{\pazocal{A}}\!\! : \; A^{n} \to A$ em A.\qed{}
        \end{definicao}

        Quando não for confuso, o mesmo símbolo será utilizado para representar um conectivo $c$ e sua interpretação $O(c) = c^{\pazocal{A}}$. Além disso, quando não houver ambiguidade, o símbolo utilizado para se referir a uma álgebra $\langle A, O \rangle$ será simplesmente o símbolo para seu domínio $A$. Ademais, caso $\Theta$ seja finita, a função $O$ será substituída pela lista de conectivos de $\Theta$. Por exemplo, uma álgebra para a assinatura $\Sigma$ da \lfium{} é escrita como $\pazocal{A} = \langle A,\land, \lor, \to, \neg, \circ \rangle$.

        \begin{observacao}
            Uma linguagem sobre uma assinatura proposicional $\Theta = \{c_{1}, \ldots, c_{n}\}$ e um conjunto enumerável de átomos $\pazocal{P} = \{p_{n} \; | \; n \in \mathbb{N} \}$ pode ser compreendida como uma álgebra da forma $\langle \pazocal{L}_{\Theta}, c_{1}\ldots, c_{n} \rangle$, onde $\pazocal{L}_{\Theta}$ é um conjunto de fórmulas bem formadas a partir dos conectivos em $\Theta$ e dos átomos em $\pazocal{P}$. Denotamos esta álgebra simplesmente por $\pazocal{L}_{\Theta}$~\cite{Sikorski1966-SIKAOF,Wojcicki1984-WJCLOP}.
        \end{observacao}

        Duas álgebras definidas sobre uma mesma assinatura proposicional são ditas \textit{similares}. Uma função (mapeamento) entre duas estruturas algebraicas similares que preserva sua estrutura é chamada de \textit{homomorfismo}. Ou seja, dadas duas álgebras similares $\langle A, O \rangle$, $\langle B, O' \rangle$ definidas sobre uma assinatura proposicional $\Theta$, um mapeamento $h : A \to B$ será um \textit{homomorfismo} caso para todo conectivo $c$ de aridade $n$ tal que $c \in \Theta$ e para todo $a_{0},\ldots,a_{n} \in A$ $h(c(a_{0},\ldots, a_{n})) = c(h(a_{0}),\ldots, h(a_{n}))$.

        \begin{definicao}[Matriz Lógica]
            Seja $\Theta$ uma assinatura proposicional. Uma \textit{matriz lógica} $\pazocal{M}$ definida sobre $\Theta$ é uma tripla $\pazocal{M} = \langle A, D, O \rangle$, tal que o par $\langle A, O \rangle$ é uma álgebra para $\Theta$ e $D$ é um subconjunto de $A$ cujos elementos são ditos \textit{designados}, estes são elementos de $A$ considerados como verdadeiros.\qed{}
        \end{definicao}

        Com isso, uma matriz lógica $\pazocal{M} = \langle A, D, O \rangle$ induz uma lógica tarskiana $\mathcal{L}$ sobre uma linguagem $\pazocal{L}_{\Theta}$ da seguinte forma: Sendo $\Gamma \cup \{\alpha\} \in \pazocal{L}_{\Theta}$, tem-se $\Gamma \vDash_{\pazocal{M}} \alpha$ sse, para todo homomorfismo $h : \pazocal{L}_{\Theta} \to A$, se $h[\Gamma] \subseteq D$ então $h(\alpha) \in D$. Em particular, $\alpha$ é uma tautologia em $\mathcal{L}$ sse $h(\alpha) \in D$ para todo homomorfismo $h$. Perceba que o homomorfismo $h$ nada mais é do que uma função que associa fórmulas da linguagem $\pazocal{L}_{\Theta}$ a valores do domínio $A$ da matriz $\pazocal{M}$.

        \begin{definicao}[Valoração]
            Seja $\pazocal{M} = \langle A, D, O \rangle$ uma matriz lógica tal que $\pazocal{M}$ define uma lógica $\mathcal{L}$ sobre a linguagem $\pazocal{L}_{\Theta}$. Um homomorfismo $h : \pazocal{L}_{\Theta} \to A$ é dito uma valoração sobre $\pazocal{M}$.\qed{}
        \end{definicao}


       Uma lógica que apresenta três elementos no domínio de sua matriz lógica é dita \textit{trivalorada}. Algumas lógicas trivaloradas introduzem um terceiro valor além da verdade e falsidade para representar uma informação desconhecida, como é o caso da lógica de Kleene~\cite{manyvalued}. A \lfium{}, por sua vez, introduz o valor $\meio{}$ além dos valores clássicos $0$ e $1$ para representar uma informação inconsistente. Ou seja, caso $\alpha$ tenha o valor $\meio{}$, então $\neg \alpha$ também terá o valor $\meio{}$.

        \begin{definicao}[Matriz lógica da \lfium{}]
            A matriz lógica $\pazocal{M}_{\lfium{}} = \langle M, D, O \rangle$ com domínio $M = \{1, \meio{}, 0\}$ e um conjunto de valores designados $D = \{1, \meio{}\}$ é definida da seguinte forma:

            \noindent
            \begin{minipage}{0.3\textwidth}
                % Implication (→)
                \[
                    \begin{array}{c|ccc}
                        \to & 1 & \frac{1}{2} & 0 \\
                        \hline
                        1           & 1 & \frac{1}{2} & 0 \\
                        \frac{1}{2} & 1 & \frac{1}{2} & 0 \\
                        0           & 1 & 1           & 1 \\
                    \end{array}
                \]
            \end{minipage}
            \begin{minipage}{0.3\textwidth}
                % Conjunction (∧)
                \[
                    \begin{array}{c|ccc}
                        \land       & 1           & \frac{1}{2} & 0 \\
                        \hline
                        1           & 1           & \frac{1}{2} & 0 \\
                        \frac{1}{2} & \frac{1}{2} & \frac{1}{2} & 0 \\
                        0           & 0           & 0           & 0 \\
                    \end{array}
                \]
            \end{minipage}
            \begin{minipage}{0.3\textwidth}
                % Disjunction (∨)
                \[
                    \begin{array}{c|ccc}
                        \lor        & 1 & \frac{1}{2} & 0           \\
                        \hline
                        1           & 1 & 1           & 1           \\
                        \frac{1}{2} & 1 & \frac{1}{2} & \frac{1}{2} \\
                        0           & 1 & \frac{1}{2} & 0           \\
                    \end{array}
                \]
            \end{minipage}

            \vspace{0.5cm}

            \begin{minipage}{0.5\textwidth}
                % Negation (¬)
                \[
                    \begin{array}{c|c}
                                    & \neg        \\
                        \hline
                        1           & 0           \\
                        \frac{1}{2} & \frac{1}{2} \\
                        0           & 1           \\
                    \end{array}
                \]
            \end{minipage}
            \begin{minipage}{0.3\textwidth}
                \[
                    \begin{array}{c|c}
                                    & \circ   \\
                        \hline
                        1           & 1         \\
                        \frac{1}{2} & 0         \\
                        0           & 1         \\
                    \end{array}
                \]
            \end{minipage}

            \noindent
            A matriz $\pazocal{M}_{\lfium{}}$ define a relação de consequência semântica $\conmat{}$, para todo $\Gamma \cup \{\phi\} \subseteq \pazocal{L}_{\Sigma}$, da seguinte forma: $\Gamma \conmat \phi$ sse, para todo homomorfismo $h : \pazocal{L}_{\Sigma} \to M$, se $h[\Gamma] \subseteq \{1, \meio{}\}$ então $h(\phi) \in \{1, \meio{}\}$. \qed{}
        \end{definicao}
        
        

    \migs{Aqui acho interessante você explicar que essa é uma semântica não determinística e explicar pq você está incluindo ela, assim como eventualmente provar que ela é intertraduzível para a semântica de matrizes (isso deve ter no livro eu creio, se não fazemos juntos essa prova)}

        \begin{definicao} [Semântica de valorações para \textbf{$\text{LFI1}$}]
            \label{def:valoracoes}
            A função $v : \pazocal{L}_{\Sigma} \to \{1, 0\}$ é uma valoração para a lógica \lfium{} caso ela satisfaça as seguintes cláusulas:
            \begin{align*}
                & v(\alpha \land \beta) = 1 \Longleftrightarrow v(\alpha) = 1 \text{ e } v(\beta) = 1\tag{\textbf{$vAnd$}}\\
                & v(\alpha \lor \beta) = 1 \Longleftrightarrow v(\alpha) = 1 \text{ ou } v(\beta) = 1\tag{\textbf{$vOr$}}\\
                & v(\alpha \to \beta) = 1 \Longleftrightarrow v(\alpha) = 0 \text{ ou } v(\beta) = 1\tag{\textbf{$vImp$}}\\
                & v(\neg \alpha) = 0 \Longrightarrow v(\alpha) = 1\tag{\textbf{$vNeg$}}\\
                & v(\circ \alpha) = 1 \Longrightarrow v(\alpha) = 0 \text{ ou } v(\neg \alpha) = 0\tag{\textbf{$vCon$}}\\
                & v(\neg \circ \alpha) = 1 \Longrightarrow v(\alpha) = 1 \text{ e } v(\neg \alpha) = 1\tag{\textbf{$vCi$}}\\
                & v(\neg \neg \alpha) = 1 \Longrightarrow v(\alpha) = 1\tag{\textbf{$vCf$}}\\
                & v(\alpha) = 1 \Longrightarrow v(\neg \neg \alpha) = 1\tag{\textbf{$vCe$}}\\
                & v(\neg (\alpha \land \beta)) = 1 \Longleftrightarrow v(\neg \alpha) = 1 \text{ ou } v(\neg \beta) = 1\tag{\textbf{$vDM_{\land}$}}\\
                & v(\neg (\alpha \lor \beta)) = 1 \Longleftrightarrow v(\neg \alpha) = 1 \text{ e } v(\neg \beta) = 1\tag{\textbf{$vDM_{\lor}$}}\\
                & v(\neg (\alpha \to \beta)) = 1 \Longleftrightarrow v(\alpha) = 1 \text{ e } v(\neg \beta) = 1\tag{\textbf{$vCIp_{\to}$}}
            \end{align*}
            O conjunto de todas as valorações será denotado por $V^{\lfium{}}$. Então, a relação de consequência semântica $\conval$ é definida, para todo $\Gamma \cup \{\phi\} \subseteq \pazocal{L}_{\Sigma}$, da seguinte forma: $\Gamma \conval \phi$ sse, para todo $v \in V^{\lfium{}}$, se $v(\gamma) = 1$ para todo $\gamma \in \Gamma$ então $v(\phi) = 1$.\qed{}
        \end{definicao}
        \helena{Explicar nome zoado das cláusulas}

        Note que, por conta de $(VNeg)$ e $(VCon)$, o valor $v(\triangle \alpha)$ {-} para $\triangle \in \{\neg, \circ\}$ {-} não é determinado pelo valor $v(\alpha)$ da subfórmula $\alpha$. Ou seja, os conectivos $\neg$ e $\circ$ apresentam um comportamento não determinístico em relação a esta semântica de valorações. Por exemplo, caso $v(\alpha)$ seja $1$, não é possível determinar o valor \migs{de} $v(\neg \alpha)$, este podendo ser tanto $0$ como $1$ (mas não ambos).
        
        \begin{lema}[Equivalência entre a semântica de Matrizes e a semântica de valorações]
            \label{lem:matval}
            Seja $v$ uma valoração em $V^{\lfium{}}$, então existe
        \end{lema}
                
\section{Metateoremas}
    \label{sec:metateoremas}
    \helena{Explicação breve dos metateoremas o que sao pra que serve etc aff q preguica mas tem q ter algo bem bonitinho -.-'}
    Antes de desenvolver as provas destes metateoremas, convém apresentar algumas definições pertinentes e provar lemas que facilitarão o desenvolvimento das provas mais extensas. Para isso, é necessário ter ciência da definição de Lógicas Tarskianas, apresentadas na Definição~\ref{def:tarski}.

    \begin{definicao}[Teoria não-trivial maximal]
        \label{def:nao-trivial_maximal}
        Seja $\mathcal{L}$ uma lógica tarskiana definida sobre uma linguagem $\mathcal{L}$ e sejam $\Gamma, \{\phi\}$ teorias de modo que $\Gamma \cup \{\phi\} \subseteq \pazocal{L}$. A teoria $\Gamma$ é dita não-trivial maximal em relação a $\phi$ em $\mathcal{L}$ se $\Gamma \nVdash_{\mathcal{L}} \phi$ mas $\Gamma, \psi \Vdash_{\mathcal{L}} \phi$ para qualquer $\psi \notin \Gamma$.\qed{}
    \end{definicao}

    \helena{Botar exemplo de teoria não-trivial maximal?} \migs{Não acho que seja necessário, mas se você tiver um pronto acho que não vai fazer mal colocar.}

    \begin{definicao}[Teoria fechada]
        \label{def:fechada}

        Seja $\mathcal{L}$ uma lógica tarskiana. Uma teoria $\Gamma$ é dita fechada em $\mathcal{L}$ se, para toda formula $\phi$, for o caso que $\Gamma \Vdash_{\mathcal{L}} \phi$ sse $\phi \in \Gamma$.\qed{}
    \end{definicao}

    \begin{lema}
        \label{lem:nao_trivial_maximal_fechada}
        Toda teoria não-trivial maximal em relação a $\phi$ em $\mathcal{L}$ é fechada em $\mathcal{L}$.
    \end{lema}

    \begin{proof}[Prova do Lema~\ref{lem:nao_trivial_maximal_fechada}]
        Seja $\Gamma$ uma teoria não-trivial maximal em relação a $\phi$ em $\mathcal{L}$. Se $\psi \in \Gamma$, então $\Gamma \Vdash_{\mathcal{L}} \psi$, já que $\mathcal{L}$ é tarskiana. Se $\Gamma \Vdash_{\mathcal{L}} \psi$, então supondo que $\psi \notin \Gamma$, temos que $\Gamma, \psi \Vdash_{\mathcal{L}} \phi$, pela Definição~\ref{def:nao-trivial_maximal}. Como $\mathcal{L}$ é tarskiana, segue que $\Gamma \Vdash_{\mathcal{L}} \phi$, o que contradiz o fato de $\Gamma$ ser não-trivial maximal em relação a $\phi$ em $\mathcal{L}$. Portanto, $\psi \in \Gamma$ e então $\Gamma$ é fechada em $\mathcal{L}$.
    \end{proof}

    
    \begin{lema}
        \label{lem:id}
        A derivação $\Gamma \conhil \alpha \to \alpha$ é válida para todo $\Gamma \cup \{\alpha\} \subseteq \pazocal{L}_{\Sigma}$.
    \end{lema}
    
    \begin{proof}[Prova do Lema~\ref{lem:id}]
        A seguinte sequência de derivação demonstra o lema:
        
        \begin{align*}
            & \text{1. } (\alpha \to ((\alpha \to \alpha) \to \alpha)) \to ((\alpha \to (\alpha \to \alpha)) \to (\alpha \to \alpha))\tag{Ax2}\\
            & \text{2. } \alpha \to ((\alpha \to \alpha) \to \alpha)\tag{Ax1}\\
            & \text{3. } \alpha \to (\alpha \to \alpha)\tag{Ax1}\\
            & \text{4. } (\alpha \to (\alpha \to \alpha)) \to (\alpha \to \alpha)\tag{MP 1,2}\\
            & \text{5. } \alpha \to \alpha\tag{MP 3,4}
        \end{align*}
    \end{proof}
    
    
    \begin{teorema}[Metateorema da dedução para $\conhil$]
        \label{teo:deducao}
        Para todo conjunto de fórmulas $\Gamma \cup \{\alpha, \beta \} \subseteq \pazocal{L}_{\Sigma}$:

        \centering
        $\Gamma, \alpha \conhil \beta \Longleftrightarrow \Gamma \conhil \alpha \to \beta$.
    \end{teorema}

    \begin{proof}[Prova do Teorema~\ref{teo:deducao}] A prova será dividida em duas partes:\\
        ($\Longleftarrow$) Supondo $\Gamma \conhil \alpha \to \beta$, então existe uma sequência de derivação $\phi_{1} \ldots \phi_{n}$ onde $\phi_{n} = \alpha \to \beta$. 
        
        A seguinte sequência de derivação completa a prova de $\Gamma, \alpha \conhil \beta$:
        \begin{align*}
            \text{1}&.~ \; \ldots\\
            & \vdots \; ~\ddots\\
            \text{$n$}&.~ \alpha \to \beta\tag{Suposição}\\
            \text{$n + 1$}&.~ \alpha\tag{Premissa}\\
            \text{$n + 2$}&.~ \beta\tag{MP $n, n + 1$}
        \end{align*}

        \noindent  ($\Longrightarrow$) Supondo $\Gamma, \alpha \conhil \beta$, então existe uma sequência de derivação $\phi_{1} \ldots \phi_{n}$ onde $\phi_{n} = \beta$ a partir do conjunto de premissas $\Gamma \cup \{\alpha\}$. A prova de $\Gamma \conhil \alpha \to \beta$ é feita pela indução no tamanho $n$ da sequência de derivação:
        \noindent  ($\Longrightarrow$) Supondo $\Gamma, \alpha \conhil \beta$, então existe uma sequência de derivação $\phi_{1} \ldots \phi_{n}$ onde $\phi_{n} = \beta$ a partir do conjunto de premissas $\Gamma \cup \{\alpha\}$. A prova de $\Gamma \conhil \alpha \to \beta$ é feita pela indução no tamanho $n$ da sequência de derivação:\\

        \noindent \textbf{\textsc{Base}} $n = 1$.
        A sequência contem somente uma fórmula $\phi_{1} = \beta$. Portanto, existem duas possibilidades:
        \begin{enumerate}
            \item $\phi_{1}$ é um axioma.
            \item $\phi_{1} \in \Gamma \cup \{\alpha\}$.
        \end{enumerate}

        \begin{provaporcasos}
            \casodeprova Provaremos $\Gamma \conhil \alpha \to \phi_{1}$ caso $\phi_{1}$ seja um axioma. 
            
                A seguinte derivação mostra $\Gamma \conhil \alpha \to \phi_{1}$:
                \begin{align*}
                    & \text{1. } \phi_{1} \tag{Axioma}\\
                    & \text{2. } \phi_{1} \to (\alpha \to \phi_{1}) \tag{Ax1}\\
                    & \text{3. } \alpha \to \phi_{1} \tag{MP 1,2}
                \end{align*}

                \casodeprova  Provaremos $\Gamma \conhil \alpha \to \phi_{1}$ caso $\phi_{1} \in \Gamma \cup \{\alpha\}$. 
                
                Existem dois casos a serem considerados:

                \begin{enumerate}
                    \item[2.1] $\phi_{1} = \alpha$
                    \item[2.2] $\phi_{1} \in \Gamma$
                \end{enumerate}

                \begin{provaporsubcasos}
                    \subcasodeprova $\phi_{1} = \alpha$. 
                    
                        É necessário mostrar $\Gamma \conhil \alpha \to \alpha$, o que foi provado pelo Lema~\ref{lem:id}.

                    \subcasodeprova $\phi_{1} \in \Gamma$.
                    
                        Então $\Gamma \conhil \alpha \to \phi_{1}$ é provado pela seguinte sequência de derivações:
                        \begin{align*}
                            & \text{1. } \phi_{1} \tag{Premissa}\\
                            & \text{2. } \phi_{1} \to (\alpha \to \phi_{1}) \tag{Ax1}\\
                            & \text{3. } \alpha \to \phi_{1} \tag{MP 1, 2}
                        \end{align*}
                \end{provaporsubcasos}
                
            \end{provaporcasos}
            
            Portanto, $\Gamma \conhil \alpha \to \phi_{1}$ segue para o caso da \textbf{\textsc{Base}}.

        \noindent \textbf{\textsc{Passo}} Hipótese de indução (HI): \textit{Para qualquer sequência de derivação $\Gamma, \alpha \conhil \beta$ de tamanho $i$, com $i < n$, tem-se $\Gamma \conhil \alpha \to \beta$}. 
        
        É preciso mostrar que $\Gamma \conhil \alpha \to \beta$ segue caso a dedução $\Gamma, \alpha \conhil \beta$ seja de tamanho $n$. 
        
        Ao analisar a obtenção de $\phi_{n} = \beta$ na sequência de derivação de $\Gamma, \alpha\conhil \phi_{n}$, existem três casos a se considerar:
        \begin{enumerate}
            \item $\phi_{n}$ é um axioma.
            \item $\phi_{n} \in \Gamma \cup \{\alpha\}$.
            \item $\phi_{n}$ é obtido por \textit{modus ponens} em duas fórmulas $\phi_{j}$ e $\phi_{k}$ com $j, k < n$.
        \end{enumerate}
        
         Os casos 1 e 2 são análogos aos casos provados na base.

         \noindent \textsc{Caso 3.} $\phi_{n}$ é obtido por \textit{modus ponens} em duas fórmulas $\phi_{j}$ e $\phi_{k}$ com $j, k < n$. 
         
         Então, $\phi_{k} = \phi_{j} \to \phi_{n}$ (ou $\phi_{j} = \phi_{k} \to \phi_{n}$, a prova para este caso é análoga). 
         
         Dada a nossa suposição de $\Gamma, \alpha \conhil \phi_{n}$, temos $\Gamma, \alpha \conhil \phi_{j}$ e $\Gamma, \alpha \conhil \phi_{j} \to \phi_{n}$ sequências de dedução anteriores à aplicação da regra do \textit{modus ponens} na linha $n$. 
         
         Então, pela (HI), temos $\Gamma \conhil \alpha \to \phi_{j}$ e $\Gamma \conhil \alpha \to (\phi_{j} \to \phi_{n})$. 
         
         A seguinte sequência de derivação mostra $\Gamma \conhil \alpha \to \phi_{n}$:
         \begin{align*}
             \text{1}&.~ \; \ldots\\
             &\vdots \; ~\ddots\\
             \text{$j$}&.~ \alpha \to \phi_{j} \tag{HI sobre $\phi_{j}$}\\
             &\vdots \; ~\ddots\\
             \text{$j + k$}&.~ \alpha \to (\phi_{j} \to \phi_{n}) \tag{HI sobre $\phi_{k}$}\\
             \text{$j + k + 1$}&.~ (\alpha \to (\phi_{j} \to \phi_{n})) \to ((\alpha \to \phi_{j}) \to (\alpha \to \phi_{n})) \tag{Ax2}\\
             \text{$j + k + 2$}&.~ (\alpha \to \phi_{j}) \to (\alpha \to \phi_{n}) \tag{MP $j + k$,$j + k + 1$}\\
              \text{$j + k + 3$}&.~ \alpha \to \phi_{n} \tag{MP $j$,$j + k + 2$}
         \end{align*}
    \end{proof}

    \begin{teorema}[Correção]
        \label{teo:correcao}
        A lógica \lfium{} é correta em relação a sua semântica de valorações, ou seja, para todo conjunto de fórmulas $\Gamma \cup \{\alpha\} \subseteq \pazocal{L}_{\Sigma}$:

        \centering
        $\Gamma \conhil \alpha \Longrightarrow \Gamma \conval \alpha$.
    \end{teorema}

    \begin{proof}[Prova do Teorema~\ref{teo:correcao}]
        Supondo $\Gamma \conhil \alpha$, existe uma sequência de derivação $\phi_{1} \ldots \phi_{n}$ onde $\phi_{n} = \alpha$. A prova de $\Gamma \conval \alpha$ é obtida por indução no tamanho $n$ da sequência de derivação:\\

        \noindent \textbf{\textsc{Base}} $n = 1$. A sequência contém somente uma fórmula $\phi_{1} = \alpha$. Portanto, existem duas possibilidades:
        \begin{enumerate}
            \item $\phi_{1}$ é um axioma.
            \item $\phi_{1} \in \Gamma$.
        \end{enumerate}
        

        % \begin{gambiarra}
            % Isso é uma grandissima gambiarra mas funciona que é uma beleza -- migs
            \newcounter{subcasosUm}
            \newcommand{\subcaso}{\refstepcounter{subcasosUm}\item[Subcaso 1.\thesubcasosUm{}.]}
        % \end{gambiarra}
        
        \migs{Mudar isso aqui para usar o ambiente geral que eu defini}

        \begin{provaporcasos}
            
            \casodeprova $\phi_{1}$ seja um axioma, então basta mostrar que para todo $v \in V^{\lfium{}}$, se $v(\gamma) = 1$ para todo $\gamma \in \Gamma$, então $v(\phi_{1}) = 1$. Como $\phi_{1}$ é um axioma, basta analisar todos os casos possíveis:

            \begin{provaporsubcasos}
                
                \subcasodeprova Provaremos $v(\phi_{1}) = 1$ para $\phi_{1} = \alpha \to (\beta \to \alpha)$.

                    Supondo $v(\alpha \to (\beta \to \alpha)) = 0$, temos $v(\alpha) = 1$ e $v(\beta \to \alpha) = 0$ por $(vImp)$. 
                        
                    Logo, $v(\beta) = 1$ e $v(\alpha) = 0$ novamente por $(vImp)$. Isto resulta numa contradição. 
                    
                    Portanto $v(\alpha \to (\beta \to \alpha)) = 1$.

                \subcasodeprova Provaremos $v(\phi_{1}) = 1$ para $\phi_{1} = (\alpha \to (\beta \to \gamma)) \to ((\alpha \to \beta) \to (\alpha \to \gamma ))$.
                
                    Supondo $v((\alpha \to (\beta \to \gamma)) \to ((\alpha \to \beta) \to (\alpha \to \gamma))) = 0$, temos, por ($vImp$), $v(\alpha \to (\beta \to \gamma)) = 1 \text{ e } v((\alpha \to \beta) \to (\alpha \to \gamma)) = 0$.

                    Portanto, por $(vImp)$, temos $v(\alpha) = 0$ ou $v(\beta \to \gamma) = 1$, e $v(\alpha \to \beta) = 1$ e $v(\alpha \to \gamma) = 0$. 
                    
                    Por $(vImp)$ segue $v(\alpha) = 1$ e $v(\gamma) = 0$, logo, $v(\beta \to \gamma) = 1$ e, portanto, $v(\beta) = 0$ ou $v(\gamma) = 1$. 
                    
                    Porém, como $v(\alpha \to \beta) = 1$ e $v(\alpha) = 1$, então $v(\beta) = 1$, o que resulta numa contradição. Logo $v((\alpha \to (\beta \to \gamma)) \to ((\alpha \to \beta) \to (\alpha \to \gamma))) = 1$.

                \subcasodeprova Provaremos $v(\phi_{1}) = 1$ para $\phi_{1} = \alpha \to (\beta \to (\alpha \land \beta))$. 

                    Supondo $v(\alpha \to (\beta \to (\alpha \land \beta))) = 0$, temos $v(\alpha) = 1$ e $v(\beta \to (\alpha \land \beta)) = 0$, por $(vImp)$, então $v(\beta) = 1$ e $v(\alpha \land \beta) = 0$ novamente por $(vImp)$. 
                    
                    Com isso, temos $v(\alpha) = 0$ ou $v(\beta) = 0$ por $(vAnd)$, mas isso resulta numa contradição, já que $v(\alpha) = 1$ e $v(\beta) = 1$. 
                    
                    Portanto $v(\alpha \to (\beta \to (\alpha \land \beta))) = 1$.

                \subcasodeprova Provaremos $v(\phi_{1}) = 1$ para $\phi_{1} = (\alpha \land \beta) \to \alpha$. 
                
                    Supondo $v((\alpha \land \beta) \to \alpha) = 0$. 
                
                    Logo $v(\alpha \land \beta) = 1$ e $v(\alpha) = 0$ por $(vImp)$. 
                    
                    Então, $v(\alpha) = 1$ e $v(\beta) = 1$ por $(vAnd)$, o que resulta numa contradição. 
                    
                    Portanto $v((\alpha \land \beta) \to \alpha) = 1$.

                \subcasodeprova Provaremos $v(\phi_{1}) = 1$ para $\phi_{1} = (\alpha \land \beta) \to \beta$. Como no caso anterior, \textit{mutatis mutandis}.

                \subcasodeprova Provaremos $v(\phi_{1}) = 1$ para $\phi_{1} = \alpha \to (\alpha \lor \beta)$. 
                
                    Supondo $v(\alpha \to (\alpha \lor \beta)) = 0$, temos $v(\alpha) = 1$ e $v(\alpha \lor \beta) = 0$, por $(vImp)$. 
                    
                    Então temos $v(\alpha) = 0$ e $v(\beta) = 0$ por $(vOr)$, o que resulta numa contradição. 
                    
                    Portanto $v(\alpha \to (\alpha \lor \beta)) = 1$.

                \subcasodeprova Provaremos $v(\phi_{1}) = 1$ para $\phi_{1} = \beta \to (\alpha \lor \beta)$. Como no caso anterior, \textit{mutatis mutandis}.

                \subcasodeprova Provaremos $v(\phi_{1}) = 1$ para $\phi_{1} = (\alpha \to \gamma) \to ((\beta \to \gamma) \to ((\alpha \lor \beta) \to \gamma))$. 
                
                    Supondo $v((\alpha \to \gamma) \to ((\beta \to \gamma) \to ((\alpha \lor \beta) \to \gamma))) = 0$, temos, por $(vImp)$, $v((\alpha \to \gamma)) = 1$ e $v(((\beta \to \gamma) \to ((\alpha \lor \beta) \to \gamma))) = 0$. 
                    
                    Portanto, novamente por $(vImp)$, temos $v(\alpha) = 0$ ou $v(\gamma) = 1$. Além disso, temos $v(\beta \to \gamma) = 1$ e $v((\alpha \lor \beta) \to \gamma) = 0$. 
                    
                    Então, temos $v(\beta) = 0$ ou $v(\gamma) = 1$. Ademais, $v(\alpha \lor \beta) = 1$ e $v(\gamma) = 0$. 
                    
                    Finalmente, por $(vOr)$, temos $v(\alpha) = 1$ ou $v(\beta) = 1$. O fato de termos $v(\gamma) = 0$ nos permite concluir $v(\alpha) = 0$ e $v(\beta) = 0$, porém isto nos dá $v(\alpha) = 1$ (já que temos $v(\alpha) = 1$ ou $v(\beta) = 1$ e também $v(\beta) = 0$), o que resulta numa contradição, pois já temos $v(\alpha) = 0$. 
                    
                    Portanto, $v((\alpha \to \gamma) \to ((\beta \to \gamma) \to ((\alpha \lor \beta) \to \gamma))) = 1$.

                \subcasodeprova Provaremos $v(\phi_{1}) = 1$ para $\phi_{1} = (\alpha \to \beta) \lor \alpha$. 
                    
                    Supondo $v((\alpha \to \beta) \lor \alpha) = 0$, então, por $(vOr)$, temos $v(\alpha \to \beta) = 0$ e $v(\alpha) = 0$. 
                    
                    Logo, por $(vImp)$, $v(\alpha) = 1$  e $v(\beta) = 0$, o que resulta numa contradição. 
                    
                    Portanto, $v((\alpha \to \beta) \lor \alpha) = 1$.

                \subcasodeprova Provaremos $v(\phi_{1}) = 1$ para $\phi_{1} = \alpha \lor \neg \alpha$. 
                
                    Supondo $v(\alpha \lor \neg \alpha) = 0$, temos por $(vOr)$, $v(\alpha) = 0$ e $v(\neg \alpha) = 0$. 
                    
                    Então, por $(vNeg)$, $v(\alpha) = 1$, o que resulta numa contradição. 
                    
                    Portanto, $v(\alpha \lor \neg \alpha) = 1$.

                \subcasodeprova Provaremos $v(\phi_{1}) = 1$ para $\phi_{1} = \circ \alpha \to (\alpha \to (\neg \alpha \to \beta))$. 
                
                    Supondo $v(\circ \alpha \to (\alpha \to (\neg \alpha \to \beta))) = 0$, então, por $(vImp)$, $v(\circ \alpha) = 1$ e $v(\alpha \to (\neg \alpha \to \beta)) = 0$. 
                    
                    Logo, por $(vCon)$, $v(\alpha) = 0$ ou $v(\neg \alpha) = 0$. Ademais, por $(vImp)$, $v(\alpha) = 1$ e $v(\neg \alpha \to \beta) = 0$. 
                    
                    Novamente por $(vImp)$, $v(\neg \alpha) = 1$ e $v(\beta) = 0$. Podemos concluir $v(\alpha) = 0$, já que temos $v(\neg \alpha) = 1$ e também temos $v(\alpha) = 0$ ou $v(\neg \alpha) = 0$. 
                    
                    Isto resulta numa contradição, pois temos $v(\alpha) = 1$ e $v(\alpha) = 0$. 
                    
                    Portanto, $v(\circ \alpha \to (\alpha \to (\neg \alpha \to \beta))) = 1$.

                \subcasodeprova Provaremos $v(\phi_{1}) = 1$ para $\phi_{1} = \neg \neg \alpha \to \alpha$. 
                    
                    Supondo $v(\neg \neg \alpha \to \alpha) = 0$, então, por $(vImp)$, $v(\neg \neg \alpha) = 1$ e $v(\alpha) = 0$. 
                    
                    Por $(vCf)$ temos $v(\alpha) = 1$, o que resulta numa contradição. 
                    
                    Portanto, $v(\neg \neg \alpha \to \alpha) = 1$.

                \subcasodeprova Provaremos $v(\phi_{1}) = 1$ para $\phi_{1} = \alpha \to \neg \neg \alpha$. 
                
                    Supondo $v(\alpha \to \neg \neg \alpha) = 0$, então, por $(vImp)$, $v(\alpha) = 1$ e $v(\neg \neg \alpha) = 0$. 
                    
                    Por $(vCe)$ temos $v(\neg \neg \alpha) = 1$, o que resulta numa contradição. 
                    
                    Portanto, $v(\alpha \to \neg \neg \alpha) = 1$.

                \subcasodeprova Provaremos $v(\phi_{1}) = 1$ para $\phi_{1} = \neg \circ \alpha \to (\alpha \land \neg \alpha)$. 
                
                    Supondo $v(\neg \circ \alpha \to (\alpha \land \neg \alpha)) = 0$, temos, por $(vImp)$, $v(\neg \circ \alpha) = 1$ e $v(\alpha \land \neg \alpha) = 0$. 
                    
                    Por $(vCi)$ temos $v(\alpha) = 1$ e $v(\neg \alpha) = 1$. Ademais, por $(vAnd)$, temos $v(\alpha) = 0$ ou $v(\neg \alpha) = 0$. 
                    
                    Podemos concluir $v(\alpha) = 0$, já que temos $v(\alpha) = 0$ ou $v(\neg \alpha) = 0$ e também temos $v(\neg \alpha) = 1$. 
                    
                    Isto resulta numa contradição, pois temos $v(\alpha) = 1$ e  $v(\alpha) = 0$. 
                    
                    Portanto, $v(\neg \circ \alpha \to (\alpha \land \neg \alpha)) = 1$.

                \subcasodeprova Provaremos $v(\phi_{1}) = 1$ para $\phi_{1} = \neg (\alpha \lor \beta) \to (\neg \alpha \land \neg \beta)$. 
                
                    Supondo $v(\neg (\alpha \lor \beta) \to (\neg \alpha \land \neg \beta)) = 0$, temos, por $(vImp)$, $v(\neg (\alpha \lor \beta)) = 1$ e $v(\neg \alpha \land \neg \beta) = 0$. 
                    
                    Por $(vDM_{\lor})$ temos $v(\neg \alpha) = 1$ e $v(\neg \beta) = 1$. Ademais, por $(vAnd)$, temos $v(\neg \alpha) = 0$ ou $v(\neg \beta) = 0$. 
                    
                    Isto, unido ao fato de termos $v(\neg \beta) = 1$, nos permite concluir $v(\neg \alpha) = 0$, o que resulta numa contradição. 
                    
                    Portanto, $v(\neg (\alpha \lor \beta) \to (\neg \alpha \land \neg \beta)) = 1$.


                \subcasodeprova Provaremos $v(\phi_{1}) = 1$ para $\phi_{1} = (\neg \alpha \land \neg \beta) \to \neg (\alpha \lor \beta)$. Como no caso anterior, \textit{mutatis mutandis}.

                \subcasodeprova Provaremos $v(\phi_{1}) = 1$ para $\phi_{1} = \neg(\alpha \land \beta) \to (\neg \alpha \lor \neg \beta)$. 
                
                Supondo $v(\neg(\alpha \land \beta) \to (\neg \alpha \lor \neg \beta)) = 0$, temos, por $(vImp)$, $v(\neg(\alpha \land \beta)) = 1$ e $v(\neg \alpha \lor \neg \beta) = 0$. 
                
                Então, por $(vDM_{\land})$, temos $v(\neg \alpha) = 1$ ou $v(\neg \beta) = 1$. Além disso, por $(vOr)$, temos $v(\neg \alpha) = 0$ e $v(\neg \beta) = 0$. 
                
                Isto nos permite concluir $v(\neg \alpha) = 1$, pois temos $v(\neg \alpha) = 1$ ou $v(\neg \beta) = 1$ e também temos $v(\neg \beta) = 0$. 
                
                Isto resulta numa contradição, pois temos $v(\neg \alpha) = 1$ e $v(\neg \alpha) = 0$. 
                
                Portanto, $v(\neg(\alpha \land \beta) \to (\neg \alpha \lor \neg \beta)) = 1$.

                \subcasodeprova Provaremos $v(\phi_{1}) = 1$ para $\phi_{1} = (\neg \alpha \lor \neg \beta) \to \neg (\alpha \land \beta)$. Como no caso anterior, \textit{mutatis mutandis}.

                \subcasodeprova Provaremos $v(\phi_{1}) = 1$ para $\phi_{1} = \neg (\alpha \to \beta) \to(\alpha \land \neg \beta)$. 
                
                Supondo $v(\neg (\alpha \to \beta) \to (\alpha \land \neg \beta)) = 0$. Por $(vImp)$ temos $v(\neg (\alpha \to \beta)) = 1$ e $v(\alpha \land \neg \beta) = 0$. 
                
                Então, por $(vCIp_{\to})$, temos $v(\alpha) = 1$ e $v(\neg \beta) = 1$. Ademais, por $(vAnd)$, temos $v(\alpha) = 0$ ou $v(\neg \beta) = 0$, o que unido ao fato de termos $v(\neg \beta) = 1$, nos permite concluir $v(\alpha) = 0$. 
                
                Isto resulta numa contradição, portanto $v(\neg (\alpha \to \beta) \to (\alpha \land \neg \beta)) = 1$.

                \subcasodeprova Provaremos $v(\phi_{1}) = 1$ para $\phi_{1} = (\alpha \land \neg \beta) \to \neg(\alpha \to \beta)$. Como no caso anterior, \textit{mutatis mutandis}.
                
            \end{provaporsubcasos}

            Com isso, o \textsc{Caso 1} está provado e $\Gamma \conval \phi_{1}$ segue caso $\phi_{1}$ seja um axioma.

            \casodeprova $\phi_{1} \in \Gamma$. Logo, se $v(\gamma) = 1$ para todo $\gamma \in \Gamma$, temos $v(\phi_{1}) = 1$. Portanto, $\Gamma \conval \phi_{1}$.

        \end{provaporcasos}

         \noindent \textbf{\textsc{Passo}} \textit{Hipótese de indução (HI): Para qualquer sequência da derivação de $\Gamma \conhil \alpha$ de tamanho $k < n$, tem-se $\Gamma \conval \alpha$}. 
         
         Portanto, é preciso mostrar que $\Gamma \conval \alpha$ segue caso a sequência de derivação de $\Gamma \conhil \alpha$ tenha tamanho $n$. Ao analisar a obtenção de $\phi_{n} = \alpha$ em $\Gamma \conhil \phi_{n}$, existem três casos a se considerar:
         
         \begin{enumerate}
            \item $\phi_{n}$ é um axioma.
            \item $\phi_{n} \in \Gamma$.
            \item $\phi_{n}$ é obtido por \textit{modus ponens} em duas fórmulas $\phi_{j}$ e $\phi_{k}$ com $j, k < n$. 
         \end{enumerate}
         
         Os casos 1 e 2 são análogos aos casos provados na base.
         
         \noindent \textsc{Caso 3.} $\phi_{n}$ é obtido por \textit{modus ponens} em duas fórmulas $\phi_{j}$ e $\phi_{k}$ com $j, k < n$. 
         
         Logo, $\phi_{k} = \phi_{j} \to \phi_{n}$ (ou $\phi{j} = \phi_{k} \to \phi_{n}$, a prova para este caso é análoga). 
         
         Dada nossa suposição de $\Gamma \conhil \phi_{n}$, então $\Gamma \conhil \phi_{j}$ e $\Gamma \conhil \phi_{j} \to \phi_{n}$. 
         
         Pela (HI), temos $\Gamma \conval \phi_{j}$ e $\Gamma \conval \phi_{j} \to \phi_{n}$. 
         
         Então, se $v(\gamma) = 1$ para todo $v(\gamma) \in \Gamma$, temos $v(\phi_{j}) = 1$ e $v(\phi_{j} \to \phi_{n}) = 1$. 
         
         Por $(vImp)$ temos $v(\phi_{j}) = 0$ ou $v(\phi_{n}) = 1$. 
         
         Isto, unido ao fato de termos $v(\phi_{j}) = 1$, nos permite concluir $v(\phi_{n}) = 1$. 
         
         Portanto $\Gamma \conval \phi_{n}$ e a prova está finalizada.

    \end{proof}
